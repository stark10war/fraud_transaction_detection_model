---
title:  "Fraud Transaction Detection EDA & Modelling"
output:
  html_document:
    df_print: paged
  html_notebook: default
  pdf_document: default
---

##                                       **About the Data**

  I found this dataset on Kaggle. It is a simulator generated dataset of mobile money transactions generated for fraud detection research . There are more than 60 lakh observations (transactions) and there are 11 variables whose descriptions are as follow:

* **step** - maps a unit of time in the real world. In this case 1 step is 1 hour of time. Total steps 744 (30              days simulation).

* **type** - CASH-IN, CASH-OUT, DEBIT, PAYMENT and TRANSFER.

* **amount** - amount of the transaction in local currency.

* **nameOrig** - customer who started the transaction

* **oldbalanceOrg** - initial balance before the transaction

* **newbalanceOrig** - new balance after the transaction

* **nameDest** - customer who is the recipient of the transaction

* **oldbalanceDest** - initial balance of recipient before the transaction.                        

* **newbalanceDest** - new balance of recipient after the transaction.

* **isFraud** - This is the transactions made by the fraudulent agents inside the simulation.

* **isFlaggedFraud** - The business model aims to control massive transfers from one account to another and                           flags illegal attempts. An illegal attempt in this dataset is an attempt to transfer                           more than 200.000 in a single transaction.


### Lets take a quick look at the data and its descriptive statistics

```{r message=FALSE, warning=FALSE, comment=FALSE, results='hide'}
library(dplyr)
library(caret)
library(ggplot2)
library(caTools)
library(randomForest)
library(rpart)
library(rpart.plot)
library(Matrix)
library(xgboost)
library(data.table)
library(magrittr)
library(Metrics)
library(gridExtra)
library(rfUtilities)
transactions<- fread("D:/Shashank R files/Fraud_detection_data/data_file.csv", header = TRUE, stringsAsFactors = TRUE)
transactions<- as.data.frame(transactions)

```


```{r message=FALSE, warning=FALSE}
head(transactions)
```

```{r}
dim(transactions)
```


```{r}
str(transactions)
```

```{r}
summary(transactions)
```
 
 
 
 
##                                **EDA** - Understanding the Data.




### Total transactions vs Fraud transactions
 
```{r}
fraud_count<- transactions %>% count(isFraud)
print(fraud_count)
```

```{r}
(fraud_count$n[2]/nrow(transactions))*100
```

There are only **8213** transactions which are actually **fraud** out of total **6362620** transactions.
 
Only around * **0.13%** * transactions are Fraud.

#### *Let's visualise it*

```{r}
barplot(prop.table(fraud_count$n)*100, names.arg = c('not fraud' ,  'fraud'), ylab = 'No of Transactions' ,main = "Fraud vs Not Fraud" ,col = 'light pink' , ylim = c(0,100))
```







### Transaction Type Plot

```{r}
ggplot(data = transactions, aes(x = type , fill = type)) + geom_bar() + labs(title = "Transactions as per Type",  x = 'Transaction Type' , y = 'No of transactions' ) +theme_classic()

```





### Transaction Types which are more likely to be Fraud

```{r message=FALSE, warning=FALSE, paged.print=FALSE}

Fraud_trans_type <- transactions %>% group_by(type) %>% summarise(fraud_transactions = sum(isFraud))

ggplot(data = Fraud_trans_type, aes(x = type,  y = fraud_transactions)) + geom_col(aes(fill = 'type'), show.legend = FALSE) + labs(title = 'Fraud transactions as Per type', x = 'Transcation type', y = 'No of Fraud Transactions') + geom_text(aes(label = fraud_transactions), size = 4, hjust = 0.5, vjust = 0) + theme_classic()

```

Its clear from the above plot that all the fraud transactions are either CASH_OUT or TRANSFER type.









```{r}
ggplot(data = transactions[transactions$isFraud==1,], aes(x = amount ,  fill =amount)) + geom_histogram(bins = 30, aes(fill = 'amount')) + labs(title = 'Fraud transaction Amount distribution', y = 'No. of Fraud transacts', x = 'Amount in Dollars')
```

The Frequency distribution of Amount of money involved in Fraud transactions is **Positively Skewed** . It is Clear that most of the fraud transactions are of **Lesser** amount.









```{r}

ggplot(data = transactions, aes(x = factor(isFraud) ,y = log1p(amount), fill = factor(isFraud))) + geom_boxplot(show.legend = FALSE) +labs(title= 'Amount- Boxplot' , x = 'isFraud') +  theme_classic()

```

The above boxplot shows that the *Amount* involved in **fraud** transactions is greater than that of in Non Fraud transactions.








```{r}
p1<- ggplot(data = transactions, aes(x = factor(isFraud) ,y = log1p(oldbalanceOrg), fill = factor(isFraud))) + geom_boxplot(show.legend = FALSE) +labs(title= 'Old balance in Origin Accounts' , x = 'isFraud') +  theme_classic()

p2 <- ggplot(data = transactions, aes(x = factor(isFraud) ,y = log1p(oldbalanceDest), fill = factor(isFraud))) + geom_boxplot(show.legend = FALSE) +labs(title= 'Old balance in Destination Accounts' , x = 'isFraud') +  theme_classic()

grid.arrange(p1, p2, nrow = 1)

```

In majority of the fraud transactions the Old balance of the Origin account from which the payments are made is **higher** than rest of the origin accounts while the Old balance in Destination accounts is Lower than rest. This is not at all a surprising observation as fraud transactions are made to * **Steal from the rich and give to the poors.!** * . 





### Distribution of transactions at different time intervals


```{r message=FALSE, warning=FALSE}
p3<- ggplot(data = transactions, aes(x = step)) + geom_histogram(bins = 700,aes(fill = 'isFraud'), show.legend = FALSE) +labs(title= 'Total transactions at different Steps (time)', y = 'No. of transactions') + theme_classic()

p4<- ggplot(data = transactions[transactions$isFraud==1,], aes(x = step)) + geom_histogram(bins =700, aes(fill = 'isFraud'), show.legend = FALSE) + theme_classic()+ labs(title= 'Fraud transactions at different steps (time)' , y = 'No. of Fraud transactions')

grid.arrange(p3, p4, ncol = 1, nrow = 2)

```

After **400 step** the total no. of transactions are very **low** but the Fraud transactions doesn't seems to be going down. This looks Surprising. Let's do some more Reasearch here.


### converting Step to Hours in 24 hours format

Each step represents 1 hour of real world and there are total 743 steps for 30 days of data . Lets convert them into 24 hours where each day has 1 to 14 hours and the pattern repeats again

```{r}
transactions$hour <- mod(transactions$step, 24)
```

```{r}
p5<- ggplot(data = transactions, aes(x = hour)) + geom_bar(aes(fill = 'isFraud'), show.legend = FALSE) +labs(title= 'Total transactions at different Hours', y = 'No. of transactions') + theme_classic()

p6<-ggplot(data = transactions[transactions$isFraud==1,], aes(x = hour)) + geom_bar(aes(fill = 'isFraud'), show.legend = FALSE) +labs(title= 'Fraud transactions at different Hours', y = 'No. of fraud transactions') + theme_classic()

grid.arrange(p5, p6, ncol = 1, nrow = 2)

```
 Look at the graphs now, The total no of transactions happening between **0 to 9 hours** are **very low**
 but Farud transactions are still happening at the same rate. Hence it can be concluded that fraud transactions are very often between **0 to 9 hours**.





## Feature Engineering 

Looking closely at the data reveled that there are certain transactions where the transaction Amount is greater than the balance available in the Origin account.

```{r message=FALSE, warning=FALSE}

 head(transactions[(transactions$amount > transactions$oldbalanceOrg)& (transactions$newbalanceDest > transactions$oldbalanceDest), c("amount","oldbalanceOrg", "newbalanceOrig", "oldbalanceDest", "newbalanceDest", "isFraud")], 10)

```


 Hence let's create a new feature called **'adjustedBalanceOrg'** and **'adjustedBalanceDest'** where

* **adjustedBalanceOrg** = newbalanceOrg + amount - oldbalanceOrg
* **adjustedBalanceDest** = oldbalanceDest + amount - newbalanceDest

```{r message=FALSE, warning=FALSE, paged.print=TRUE}
#Creating new features
transactions$adjustedBalanceOrg<-round(transactions$newbalanceOrig+transactions$amount-transactions$oldbalanceOrg, 2)

transactions$adjustedBalanceDest<-round(transactions$oldbalanceDest+transactions$amount-transactions$newbalanceDest, 2)

colnames(transactions)

```

### Getting Required features

Since all the fraud transactions only occur in CASH_OUT and TRANSFER type, we can only extract those transaction types for modeilling
```{r}
# Filtering only CASH_OUT and TRANSFER transactions andd droping irrelevant features
transactions1<- transactions %>% 
                select( -one_of('step','nameOrig', 'nameDest', 'isFlaggedFraud')) %>%
                filter(type %in% c('CASH_OUT','TRANSFER'))

```


### Encoding Dummy variables for transaction type

```{r message=FALSE, warning=FALSE}
library(fastDummies)
transactions1 <- dummy_cols(transactions1, select_columns = 'type')
transactions1$isFraud <- as.factor(transactions1$isFraud)
colnames(transactions1)

```
Now we have one 2 columns **type_TRANSFER** and **type_CASH_OUT** encoded into numeric format.


## Modelling

Let's begin with building a Model to predict the fraud transactions.

### Splitting the train and test set.

```{r message=FALSE, warning=FALSE}
set.seed(1)
spl <- sample.split(transactions1$isFraud, 0.8)
transactions_train <- transactions1[spl == TRUE,]
transactions_test <- transactions1[spl == FALSE,]

print('Train Set: ')
table(transactions_train$isFraud)/nrow(transactions_train)*100
print('Test Set: ')
table(transactions_test$isFraud)/nrow(transactions_test)*100

```



### Training



## Decision tree 
```{r message=FALSE, warning=FALSE}

set.seed(1)
fit_tree <- rpart(isFraud~., data = transactions_train)

```



### Predicting on test set

```{r}
pred <- predict(fit_tree, newdata = transactions_test[,-6], type ='class')

confusion<-confusionMatrix(pred, transactions_test$isFraud, positive = '1', mode = 'everything')
print(confusion)
```

### Ploting the Tree
```{r}
 prp(fit_tree)

```




### Plotting variable importance

```{r}
importance_tree <- data.frame(Variables = names(fit_tree$variable.importance), importance = fit_tree$variable.importance, row.names = NULL)

ggplot(data = importance_tree , aes(y = importance , x = Variables, fill = Variables))+ geom_col() + coord_flip() + labs(title= 'Variiable importance plot')+ theme_classic()
```







## XGboost

### Converting the data to XGB.Dmatrix format

```{r}
x_train <- as.matrix(transactions_train[,-6])
y_train <- as.numeric(as.character(transactions_train$isFraud))

x_test <- as.matrix((transactions_test[,-6]))
y_test <- as.numeric(as.character(transactions_test$isFraud))


train_xg<- xgb.DMatrix(data = x_train, label = y_train)
test_xg <- xgb.DMatrix(data = x_test, label = y_test)

```



### Training XGboost

### XGboost cross validation 
```{r}

#calculating weights for positive class
n_pos<-nrow(transactions_train[transactions_train$isFraud == 1,])
n_neg<- nrow(transactions_train[transactions_train$isFraud == 0,])

weight <-n_neg/n_pos

#Parameter Grid
param = list(booster = "gbtree", max_depth = 2, eval_metric = 'error',  objective = "binary:logistic" ,scale_pos_weight = weight )

set.seed(1)

xgb_cv <- xgb.cv(params = param, data = train_xg, nrounds = 20, nfold = 5, metrics = 'error' )


```


### Train and Validation Errors plot for 20 Rounds

```{r}
xgb_cv$evaluation_log %>% ggplot(aes(x = iter ,y = train_error_mean, colour = 'blue')) + geom_line() + geom_line(aes(y= test_error_mean , colour = 'red')) + scale_color_manual(labels = c("Train error", "Test error"), values = c('blue', 'red')) 
                          

```

The optimal no. of rounds given by the xgboost seems to be 11 Rounds where the error on both **train** and **validation set** is minimum, also the model **doesn't** seems to be **overfitting**, as both the train and validation error follows the **same trend**.



## Fitting the final model with watchlist for train and test set.

lets fit the XGboost model with a watchlist for train and test set which will also output the train and test set errors. 

```{r}


param = list(booster = "gbtree", max_depth = 2, eval_metric = 'error',  objective = "binary:logistic", scale_pos_weight = weight)
set.seed(1)
fit <- xgb.train(data = train_xg, params = param, nrounds = 19 , watchlist = list(test_set = test_xg, train_set = train_xg))

```



# Train and Test set error plot

```{r}
fit$evaluation_log %>% ggplot(aes(x = iter ,y = train_set_error, colour = 'blue')) + geom_line() +geom_line(aes(y= test_set_error , colour = 'red')) + scale_color_manual(labels = c("Train error", "Test error"), values = c('blue', 'red'))
```

seems like the the error is highly **minimized** **without any Overfitting**. as the Test set on which the model is not trained is also giving the same error as the train set. Hope the accuracy will also be same for both train and test sets.


## Confusion Matrix

```{r}
pred_xgb <- predict(fit, newdata = test_xg)
pred1<- ifelse(pred_xgb>0.5,1,0)
confusionMatrix(pred1, y_test, positive = '1',mode = 'everything')


```
**Hurrey!!!**, the **confusion matrix** of the test set looks very impressive. The **FALSE POSITIVE (Specificity)** rate is **100%** while there are only 9 **FALSE NEGATIVES** (Positive class being '1').

** ACCURACY ** = **0.9973**



### XGB variable Importance Plot

```{r message=FALSE, warning=FALSE}
xgb_importance <- xgb.importance(feature_names = names(transactions_train[,-6]) , model = fit)

xgb.ggplot.importance(xgb_importance)
```


## Let's see the miss classified Transactions
```{r}
transactions_test$prediction <- pred1
transactions_test$probabilities <- pred_xgb
transactions_test[transactions_test$prediction!=transactions_test$isFraud,]

```


Need your feedback and Suggestions.!!!

THANKS,

**BY - SHASHANK TANWAR**

#         THE END   



